{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import html\n",
    "from difflib import SequenceMatcher\n",
    "from collections import Counter\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Initialize lemmatizer and stopwords\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Preprocess each sentence\n",
    "    processed_sentences = []\n",
    "    for sentence in sentences:\n",
    "        # Tokenize words and convert to lowercase\n",
    "        words = word_tokenize(sentence.lower())\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        words = [lemmatizer.lemmatize(word) for word in words if word.isalnum() and word not in stop_words]\n",
    "        \n",
    "        processed_sentences.append(' '.join(words))\n",
    "    \n",
    "    return processed_sentences, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name().lower())\n",
    "    return synonyms\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "def lcs_similarity(s1, s2):\n",
    "    matcher = SequenceMatcher(None, s1, s2)\n",
    "    match = matcher.find_longest_match(0, len(s1), 0, len(s2))\n",
    "    lcs_length = match.size\n",
    "    max_length = max(len(s1), len(s2))\n",
    "    return lcs_length / max_length if max_length > 0 else 0\n",
    "\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    processed_sentences = []\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence.lower())\n",
    "        words = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in words if word.isalnum() and word not in stop_words]\n",
    "        processed_sentences.append(' '.join(words))\n",
    "    \n",
    "    return processed_sentences, sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_texts(text1, text2):\n",
    "    processed_sentences1, original_sentences1 = preprocess_text(text1)\n",
    "    processed_sentences2, original_sentences2 = preprocess_text(text2)\n",
    "    \n",
    "    all_sentences = processed_sentences1 + processed_sentences2\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_sentences)\n",
    "    \n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    \n",
    "    matches = []\n",
    "    total_chars = sum(len(sent) for sent in original_sentences1)\n",
    "    matched_chars = 0\n",
    "    \n",
    "    for i, (proc_sent1, orig_sent1) in enumerate(zip(processed_sentences1, original_sentences1)):\n",
    "        for j, (proc_sent2, orig_sent2) in enumerate(zip(processed_sentences2, original_sentences2)):\n",
    "            cosine_sim = similarity_matrix[i][j + len(processed_sentences1)]\n",
    "            jaccard_sim = jaccard_similarity(set(proc_sent1.split()), set(proc_sent2.split()))\n",
    "            lcs_sim = lcs_similarity(proc_sent1, proc_sent2)\n",
    "            \n",
    "            # Check for synonym overlap\n",
    "            words1 = set(proc_sent1.split())\n",
    "            words2 = set(proc_sent2.split())\n",
    "            synonym_overlap = sum(1 for w1 in words1 for w2 in words2 if w2 in get_synonyms(w1))\n",
    "            synonym_sim = synonym_overlap / max(len(words1), len(words2)) if max(len(words1), len(words2)) > 0 else 0\n",
    "            \n",
    "            # Combine similarity scores\n",
    "            combined_sim = (cosine_sim + jaccard_sim + lcs_sim + synonym_sim) / 4\n",
    "            \n",
    "            if combined_sim >= 0.36:\n",
    "                if combined_sim >= 0.8:\n",
    "                    color = 'dark_green'\n",
    "                elif combined_sim >= 0.7:\n",
    "                    color = 'medium_green'\n",
    "                else:\n",
    "                    color = 'light_green'\n",
    "                matches.append((orig_sent1, orig_sent2, color, combined_sim))\n",
    "                matched_chars += len(orig_sent1)\n",
    "    \n",
    "    similarity_percentage = (matched_chars / total_chars) * 100 if total_chars > 0 else 0\n",
    "    \n",
    "    return matches, similarity_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compare_texts(text1, text2):\n",
    "#     # Preprocess both texts\n",
    "#     processed_sentences1, original_sentences1 = preprocess_text(text1)\n",
    "#     processed_sentences2, original_sentences2 = preprocess_text(text2)\n",
    "    \n",
    "#     # Combine all sentences for vectorization\n",
    "#     all_sentences = processed_sentences1 + processed_sentences2\n",
    "    \n",
    "#     # Create TF-IDF vectors\n",
    "#     vectorizer = TfidfVectorizer()\n",
    "#     tfidf_matrix = vectorizer.fit_transform(all_sentences)\n",
    "    \n",
    "#     # Calculate cosine similarity between sentences\n",
    "#     similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "#     # Find matches and similar phrases\n",
    "#     matches = []\n",
    "#     total_chars = sum(len(sent) for sent in original_sentences1)\n",
    "#     matched_chars = 0\n",
    "    \n",
    "#     for i, (proc_sent1, orig_sent1) in enumerate(zip(processed_sentences1, original_sentences1)):\n",
    "#         for j, (proc_sent2, orig_sent2) in enumerate(zip(processed_sentences2, original_sentences2)):\n",
    "#             similarity = similarity_matrix[i][j + len(processed_sentences1)]\n",
    "#             if similarity == 1.0:\n",
    "#                 matches.append((orig_sent1, orig_sent2, 'dark_green'))\n",
    "#                 matched_chars += len(orig_sent1)\n",
    "#             elif similarity > 0.8:\n",
    "#                 matches.append((orig_sent1, orig_sent2, 'medium_green'))\n",
    "#                 matched_chars += len(orig_sent1)\n",
    "#             elif similarity > 0.5:\n",
    "#                 matches.append((orig_sent1, orig_sent2, 'light_green'))\n",
    "#                 matched_chars += len(orig_sent1)\n",
    "    \n",
    "#     similarity_percentage = (matched_chars / total_chars) * 100 if total_chars > 0 else 0\n",
    "    \n",
    "#     return matches, similarity_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_text_html(text, matches, is_text1=True):\n",
    "    highlighted_text = text\n",
    "    \n",
    "    color_map = {\n",
    "        'dark_green': '#00B050',\n",
    "        'medium_green': '#92D050',\n",
    "        'light_green': '#C6E0B4'  # New light green color\n",
    "    }\n",
    "    \n",
    "    for sent1, sent2, color, _ in matches:\n",
    "        html_color = color_map[color]\n",
    "        sent_to_replace = sent1 if is_text1 else sent2\n",
    "        highlighted_text = highlighted_text.replace(\n",
    "            sent_to_replace, \n",
    "            f'<span style=\"background-color: {html_color};\">{html.escape(sent_to_replace)}</span>'\n",
    "        )\n",
    "    \n",
    "    # Replace newlines with <br> tags to maintain line spacing\n",
    "    highlighted_text = highlighted_text.replace('\\n', '<br>')\n",
    "    \n",
    "    return highlighted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_html_output(text1, text2, highlighted_text1, highlighted_text2, similarity_percentage, matches):\n",
    "    html_content = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "        <title>Plagiarism Detection Result</title>\n",
    "        <style>\n",
    "            body {{ font-family: Arial, sans-serif; line-height: 1.6; padding: 20px; }}\n",
    "            h1 {{ color: #333; }}\n",
    "            .text-container {{ display: flex; justify-content: space-between; }}\n",
    "            .text-box {{ width: 48%; border: 1px solid #ccc; padding: 10px; margin-bottom: 20px; }}\n",
    "            h2 {{ color: #444; }}\n",
    "            .similarity {{ font-size: 1.2em; font-weight: bold; margin-bottom: 20px; }}\n",
    "            .legend {{ margin-bottom: 20px; }}\n",
    "            .legend-item {{ display: inline-block; margin-right: 20px; }}\n",
    "            .color-box {{ display: inline-block; width: 20px; height: 20px; margin-right: 5px; vertical-align: middle; }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Content Similarity Checker</h1>\n",
    "        <div class=\"similarity\">Similarity Percentage: {similarity_percentage:.2f}%</div>\n",
    "        <div class=\"legend\">\n",
    "            <div class=\"legend-item\">\n",
    "                <span class=\"color-box\" style=\"background-color: #00B050;\"></span>\n",
    "                High Similarity (>=0.8)\n",
    "            </div>\n",
    "            <div class=\"legend-item\">\n",
    "                <span class=\"color-box\" style=\"background-color: #92D050;\"></span>\n",
    "                Medium Similarity (0.7-0.79)\n",
    "            </div>\n",
    "            <div class=\"legend-item\">\n",
    "                <span class=\"color-box\" style=\"background-color: #C6E0B4;\"></span>\n",
    "                Low Similarity (0.5-0.69)\n",
    "            </div>\n",
    "        </div>\n",
    "        <div class=\"text-container\">\n",
    "            <div class=\"text-box\">\n",
    "                <h2>Text 1</h2>\n",
    "                <p>{highlighted_text1}</p>\n",
    "            </div>\n",
    "           <div class=\"text-box\">\n",
    "                <h2>Text 2</h2>\n",
    "                <p>{highlighted_text2}</p>\n",
    "            </div>\n",
    "        </div>\n",
    "        <h2>Detailed Matches</h2>\n",
    "        <ul>\n",
    "            {''.join(f'<li>Similarity: {sim:.2f} - Text 1: \"{s1}\" | Text 2: \"{s2}\"</li>' for s1, s2, _, sim in matches)}\n",
    "        </ul>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    return html_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Percentage: 46.60%\n",
      "HTML output has been saved to 'plagiarism_detection_result.html'\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "text1 = \"\"\"While Canva‚Äôs graphic design platform is blinkin‚Äô amazing, I found myself in a pool of confusion when trying to add an audio clip in my presentation. Why should such a little thing send me on a rollercoaster of emotions? Let me explain! 2/\n",
    "\n",
    "You know how we always groan when our electronicsasters start playing up, right? ‚ÄòWhy this now? Or why can‚Äôt I find that little button?‚Äô Like that time when I desperately needed audio in my Spanish presentation for my narration. It began driving me up the wall. 3/\n",
    "\n",
    "After panicking, I remembered seeing a small ‚Äòhelp‚Äô button in the corner of the Canva interface. \"Help and documentation, they call it\", AKA the lifesaver of my presentation. Isn‚Äôt it amazing, you got someone‚Äôs got your back when you‚Äôre lost in a sea of buttons and features? 4/\n",
    "\n",
    "So, I clicked on it. It quickly redirected me to a page full of written guidelines, FAQs, and steps on how to navigate their features. Isn‚Äôt it brilliant that you don‚Äôt need to decode stuff on your own when you‚Äôre already freaking out about your racist sounding Spanish accent? 5/\n",
    "\n",
    "I started scrolling down the help page and I loved how neatly it was arranged. A bunch of categories perfectly pointing out where to go for help based on your particular problem. But that obviously wasn‚Äôt enough to save my drowning presentation and time-sensitive predicament! 6/\n",
    "\n",
    "I was still unable to find how to add audio, and then it hit me! The search bar, why didn‚Äôt I think of it sooner? I quickly typed in ‚Äòaudio‚Äô and pressed enter. A plethora of relevant articles popped up. Is there a better feeling than your sinking ship finally seeing land? 7/\n",
    "\n",
    "I was greeted with a stepwise guide about how and where to add the audio. The way everything was laid out made it super easy to follow. It was the perfect antidote to my rising panic. Looking at the clear instructions, I felt like I was given a secret treasure map. 8/\n",
    "\n",
    "I quickly went back to the interface and followed the instructions. The sense of triumph and relief when I finally saw the audio icon on the panel! It was like finding water in a desert. I excitedly uploaded my audio clip and gave it a play. A wave of euphoria hit me! 9/\n",
    "\n",
    "I finally successfully adding my audio to the slides, and by following the instructions in the documentation, it was simpler than I initially thought! Who could‚Äôve thought a text box could hold such immense power of peace? Now, I knew the solution to my puzzle. 10/\n",
    "\n",
    "So why did I just take you through my trial of the Canva audio feature? It‚Äôs simple! My story is a prime example of why help and documentation is such an important usability heuristic. It's a simple add-on with a powerful function: to assist users in their time of need. 11/\"\"\"\n",
    "\n",
    "text2 = \"\"\"I found myself super confused when trying to add an audio clip in my oral presentation.Why can‚Äôt I find that little button? I desperately NEEDED audio in my Spanish presentation for my narration. But it turns out most applications have solutions for when users get stuck. Let me explain! 2/\n",
    "\n",
    "I couldn't find the option for adding in my own audio anywhere! I couldn't find the option for adding in my own audio anywhere! After panicking, I remembered seeing a small ‚Äòhelp‚Äô button in the corner of the Canva interface. 3/\n",
    "\n",
    "So, I clicked on it. It quickly redirected me to a page full of written guidelines, FAQs, and steps on how to navigate their features. 4/\n",
    "\n",
    "I started looking around help page and I loved how neatly it was arranged. The first thing I saw was a big search bar. Underneath it, was a couple of categories pointing out where to go for help based on your particular problem. I just quickly typed in ‚Äòaudio‚Äô and pressed enter. 5/\n",
    "\n",
    "A bunch of relevant topics popped up. I chose the first option ‚Äìadd voiceover‚Äì and was greeted with a guide about how and where to add the audio. It turned out the feature was super hidden in the uploads tab. ü§¶üèª‚Äç‚ôÄÔ∏è 6/\n",
    "\n",
    "The way everything was listed out in short numbered steps made it super easy to follow. I went right back to the interface and followed the instructions. I excitedly uploaded my audio clip and gave it a play. YAY now the presentation included my somewhat okay Spanish accent! 7/\n",
    "\n",
    "I successfully added my audio to the slides, and by following the instructions in the documentation, it was simpler than I initially thought! Who could‚Äôve thought a search box could hold such immense power of peace? 8/\n",
    "This whole process is the core of ‚ÄúHelp and Documentation‚Äù, an important feature that designers add in to ensure users have support. Everything is designed to be easy to use ‚Äìbut if there is an issue that comes up, help is where to go. 9/\n",
    "\n",
    "Once a user resorts to a help feature, designers make sure it's easy to follow. It‚Äôs simple! They make directions short, broken down into steps, and clear. Just like the short list of clicks I was given to follow. 10/\"\"\"\n",
    "\n",
    "matches, similarity_percentage = compare_texts(text1, text2)\n",
    "highlighted_text1 = highlight_text_html(text1, matches, is_text1=True)\n",
    "highlighted_text2 = highlight_text_html(text2, matches, is_text1=False)\n",
    "html_output = generate_html_output(text1, text2, highlighted_text1, highlighted_text2, similarity_percentage, matches)\n",
    "\n",
    "# Save the HTML output to a file\n",
    "with open('plagiarism_detection_result.html', 'w', encoding='utf-8') as f:\n",
    "    f.write(html_output)\n",
    "\n",
    "print(f\"Similarity Percentage: {similarity_percentage:.2f}%\")\n",
    "print(\"HTML output has been saved to 'plagiarism_detection_result.html'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
